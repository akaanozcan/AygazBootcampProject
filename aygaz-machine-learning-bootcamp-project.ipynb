{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3478314,"sourceType":"datasetVersion","datasetId":2093649}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score\nfrom sklearn.model_selection import ParameterGrid\n\nimport seaborn as sns\nimport time\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-19T20:53:35.772067Z","iopub.execute_input":"2024-09-19T20:53:35.773175Z","iopub.status.idle":"2024-09-19T20:53:35.794485Z","shell.execute_reply.started":"2024-09-19T20:53:35.773135Z","shell.execute_reply":"2024-09-19T20:53:35.793579Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/online-payments-fraud-detection-dataset/PS_20174392719_1491204439457_log.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/online-payments-fraud-detection-dataset/PS_20174392719_1491204439457_log.csv\")\ndf_2 = pd.read_csv(\"/kaggle/input/online-payments-fraud-detection-dataset/PS_20174392719_1491204439457_log.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:53:35.796198Z","iopub.execute_input":"2024-09-19T20:53:35.797166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info() # Sütunları ve veri tiplerini gösterir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10) # Veri setindeki ilk 10 satırı gösterir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum() # Sütunlardaki boş (null) değer sayısını gösterir. \n# Eğer boş değer varsa gerekli yöntemlerle doldurulmalıdır. Boş değer yoksa sıkıntı yoktur.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().apply(lambda x: x.apply('{0:.2f}'.format)) #Sütunlarla ilgili çeşitli sayısal bilgiler veriyor\n# df.describe() yapınca tüm bilgiler bilimsel gösterim şeklinde verildiğinden onları floata çevirdim","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['isFraud'] == 1]['amount'].describe().apply(lambda x: '{0:.2f}'.format(x)) # Fraud işlemlerde amount hakkında genel bilgi verir ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fraud ve fraud olmayan işlemlerin yüzdelerini pie chart ile gösterir\n\ntotal = len(df['isFraud'])\ncount_0 = df['isFraud'].value_counts()[0]\ncount_1 = df['isFraud'].value_counts()[1]\nprint(count_1)\n\nper_count_0 = (count_0 / total) * 100\nper_count_1 = (count_1 / total) * 100\n\nlabels = ['Not Fraud', 'Fraud']\nsizes = [per_count_0, per_count_1]\ncolors = ['green', 'red']\n\nfig, ax = plt.subplots()\nax.pie(sizes, labels = labels, colors = colors, autopct='%1.1f%%')\nplt.title('Fraud vs Not Fraud Transactions')\nplt.show()\nprint('Percentage of Frauds:', per_count_1)\nprint('Percentage of Not Frauds:', per_count_0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fraud işlemlerin fiyat aralıklarına göre dağılımının bar chart ile gösterimi\n\nbins = [0, 100000, 500000, 1000000, float('inf')]\nlabels = ['0-100K', '100K-500K', '500K-1M', '1M+']\n\n# Fraud işlemleri için 'amount' sütununu doğrudan gruplandırma yapılması\nfraud_df = df[df['isFraud'] == 1]\n\n# Yeni sütun oluşturmadan pd.cut ile gruplandırma ve sayım işlemi\nfraud_count_by_amount_range = pd.cut(fraud_df['amount'], bins=bins, labels=labels, right=False).value_counts().sort_index()\n\nplt.figure(figsize=(8, 6))\nax = fraud_count_by_amount_range.plot(kind='bar', color='red', edgecolor='black')\n\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width() / 2, \n            p.get_height() + 1,\n            int(p.get_height()),  # sayının integer formatında gösterilmesi\n            ha='center', va='bottom')\n\nplt.title('Fraud Transactions Count by Amount Range')\nplt.xlabel('Amount Range')\nplt.ylabel('Number of Fraud Transactions')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#isFlaggedFraud sütunundaki tahminlerin doğruluğunun oranınım pie chart ile gösterimi\n\ntrueFlag = ((df['isFraud'] == df['isFlaggedFraud'])).sum()\n\nfalseFlag = ((df['isFraud'] != df['isFlaggedFraud'])).sum()\n\ntotalDatas = len(df['isFraud'])\ntotal = trueFlag + falseFlag\n\ntrue_percentage = round((trueFlag / totalDatas) * 100, 2)\nfalse_percentage = round((falseFlag / totalDatas) * 100, 2)\n\nlabels = ['True Predictions', 'False Predictions']\nsizes = [true_percentage, false_percentage]\ncolors = ['green', 'red']\nexplode = (0, 0.1)\n\nfig, ax = plt.subplots()\nax.pie(sizes, explode=explode, labels=labels, colors = colors, autopct='%1.2f%%',\n       shadow=True, startangle=90)\nplt.title('True vs False Predictions')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"let = LabelEncoder() #Numerik olmayan veriler öğrenme algoritmaları için sorun yaratabilir\n#String veriler var ve bunları numeriğe çevirmek için label encoder fonksiyonu çağrılır.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['type'] = let.fit_transform(df['type']) #Veriler numeriğe dönüştürülür\ncategory_mapping = dict(zip(let.classes_, let.transform(let.classes_))) #Dictionary veri yapısı kullanılarak hangi stringin hangi numerik değer aldığı gösterilir.\nprint(category_mapping)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Karmaşıklığı azaltıp algoritmanın performansı için \n\n#Denetimsiz öğrenme \ndf_2.drop(['nameOrig', 'nameDest', 'isFraud'], axis=1, inplace=True)\n\n#Denetimli öğrenme\ndf.drop(['nameOrig', 'nameDest'], axis=1, inplace=True) \ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Korelasyon haritasını gösterir\ncorr_matrix = df.corr()\nplt.figure(figsize=(20,15))\nsns.heatmap(corr_matrix, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Denetimli öğrenme\ny = df['isFraud'].values\nX = df.drop('isFraud', axis=1).values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler() #Veriler farklı ölçeklerde olduğunda algoritmalara zorluk çıkartır. StandarScaler ile değerler 0 ile 1 arasında ölçeklenir ve bu da algoritmalar için yararlıdır\nX_train = scaler.fit_transform(X_train)\n\n#Denetimsiz öğrenme\nscaler_2 = StandardScaler()\ndf_scaled = scaler_2.fit_transform(df_2[['step', 'type', 'amount', 'isFlaggedFraud']]) #Korelasyon matrisinde değeri yüksek çıkan 4 sütun","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Yaptığım denemelerde en iyi sonucu verdiği için lojistik regresyonu seçtim. Tahmin yaptırdım ve değerlendirme metrikleriyle analiz ettim.\nlr = LogisticRegression(max_iter=1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Denetimsiz öğrenme\nparameters = {'C': [0.1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\nrandom_search = RandomizedSearchCV(\n    estimator=lr,\n    param_distributions=parameters,\n    n_iter=10,\n    cv=5,  # 5 katlamalı çapraz doğrulama\n    n_jobs=-1,  # Tüm işlemcileri kullan\n    verbose=1,\n    random_state=42\n)\n\nrandom_search.fit(X_train, y_train)\n\n# En iyi parametreleri ve skoru yazdıralım\nprint(\"En iyi parametreler:\", random_search.best_params_)\nprint(\"En iyi doğruluk skoru:\", random_search.best_score_)\n\n# En iyi model ile tahmin\nbest_model = random_search.best_estimator_\ny_pred = best_model.predict(X_test)\nlr_accuracy = accuracy_score(y_test, y_pred)\nlr_precision = precision_score(y_test, y_pred)\nlr_recall = recall_score(y_test, y_pred)\nlr_f1 = f1_score(y_test, y_pred)\n\nprint(\"Logistic Regression Classifier Performance:\")\nprint(\"Accuracy score: \", lr_accuracy)\nprint(\"Precision:\", lr_precision)\nprint(\"Recall:\", lr_recall)\nprint(\"F1 Score:\", lr_f1)\n\nlr_cm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix = lr_cm, display_labels = lr.classes_)\ndisp.plot()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Denetimli öğrenme\nparam_grid = {\n    'eps': [0.3, 0.5, 0.7],\n    'min_samples': [5, 10, 15]\n}\n\nbest_eps = None\nbest_min_samples = None\nbest_silhouette_score = -1  # Silhouette skoru maksimuma çıkarılacak\nbest_dbscan_model = None\nbest_labels = None\n\nfor params in ParameterGrid(param_grid):\n    dbscan = DBSCAN(eps=params['eps'], min_samples=params['min_samples'])\n    labels = dbscan.fit_predict(X_preprocessed)\n    \n    # Eğer tek bir küme varsa (ya da sadece noise varsa), silhouette score hesaplanamaz\n    if len(set(labels)) > 1:\n        # Silhouette skoru ile değerlendirme\n        score = silhouette_score(X_preprocessed, labels)\n        print(f\"DBSCAN (eps={params['eps']}, min_samples={params['min_samples']}): Silhouette Score: {score}\")\n        \n        if score > best_silhouette_score:\n            best_silhouette_score = score\n            best_eps = params['eps']\n            best_min_samples = params['min_samples']\n            best_dbscan_model = dbscan\n            best_labels = labels\n\n# Optimize edilmiş modeli kullanarak nihai kümeleme\nprint(f\"En İyi Parametreler: eps={best_eps}, min_samples={best_min_samples}\")\nprint(f\"En İyi Silhouette Skoru: {best_silhouette_score}\")\n\n# Nihai küme etiketlerini DataFrame'e ekleme\ndf_2['DBSCAN_Label'] = best_labels\n\n# Anormal (fraud) verileri belirleme (DBSCAN'de -1 anormal verileri temsil eder)\nfraud_cases = df_2[df_2['DBSCAN_Label'] == -1]\n\nprint(\"Anormal (fraud) veriler:\")\nprint(fraud_cases.head())\n\n# Silhouette skoru ile değerlendirme\nsilhouette_avg = silhouette_score(X_preprocessed, best_labels)\nprint(f\"Final Silhouette Score: {silhouette_avg}\")\n\n# Davies-Bouldin İndeksi ile değerlendirme (daha düşük, daha iyi demektir)\ndavies_bouldin_avg = davies_bouldin_score(X_preprocessed, best_labels)\nprint(f\"Davies-Bouldin Score: {davies_bouldin_avg}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}