{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3478314,"sourceType":"datasetVersion","datasetId":2093649}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.cluster import DBSCAN\n\nimport seaborn as sns\nimport time\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-19T20:47:15.299243Z","iopub.execute_input":"2024-09-19T20:47:15.300011Z","iopub.status.idle":"2024-09-19T20:47:16.868811Z","shell.execute_reply.started":"2024-09-19T20:47:15.299956Z","shell.execute_reply":"2024-09-19T20:47:16.867923Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/online-payments-fraud-detection-dataset/PS_20174392719_1491204439457_log.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/online-payments-fraud-detection-dataset/PS_20174392719_1491204439457_log.csv\")\ndf_2 = pd.read_csv(\"/kaggle/input/online-payments-fraud-detection-dataset/PS_20174392719_1491204439457_log.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:16.870626Z","iopub.execute_input":"2024-09-19T20:47:16.871085Z","iopub.status.idle":"2024-09-19T20:47:23.315999Z","shell.execute_reply.started":"2024-09-19T20:47:16.871049Z","shell.execute_reply":"2024-09-19T20:47:23.312504Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/online-payments-fraud-detection-dataset/PS_20174392719_1491204439457_log.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/online-payments-fraud-detection-dataset/PS_20174392719_1491204439457_log.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n","File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."],"ename":"ParserError","evalue":"Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.","output_type":"error"}]},{"cell_type":"code","source":"df.info() # Sütunları ve veri tiplerini gösterir","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.316967Z","iopub.status.idle":"2024-09-19T20:47:23.317488Z","shell.execute_reply.started":"2024-09-19T20:47:23.317216Z","shell.execute_reply":"2024-09-19T20:47:23.317244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10) # Veri setindeki ilk 10 satırı gösterir","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.319599Z","iopub.status.idle":"2024-09-19T20:47:23.320128Z","shell.execute_reply.started":"2024-09-19T20:47:23.319864Z","shell.execute_reply":"2024-09-19T20:47:23.319889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum() # Sütunlardaki boş (null) değer sayısını gösterir. \n# Eğer boş değer varsa gerekli yöntemlerle doldurulmalıdır. Boş değer yoksa sıkıntı yoktur.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.321663Z","iopub.status.idle":"2024-09-19T20:47:23.322178Z","shell.execute_reply.started":"2024-09-19T20:47:23.321898Z","shell.execute_reply":"2024-09-19T20:47:23.321923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().apply(lambda x: x.apply('{0:.2f}'.format)) #Sütunlarla ilgili çeşitli sayısal bilgiler veriyor\n# df.describe() yapınca tüm bilgiler bilimsel gösterim şeklinde verildiğinden onları floata çevirdim","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.323467Z","iopub.status.idle":"2024-09-19T20:47:23.323963Z","shell.execute_reply.started":"2024-09-19T20:47:23.323707Z","shell.execute_reply":"2024-09-19T20:47:23.323731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['isFraud'] == 1]['amount'].describe().apply(lambda x: '{0:.2f}'.format(x)) # Fraud işlemlerde amount hakkında genel bilgi verir ","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.324820Z","iopub.status.idle":"2024-09-19T20:47:23.325450Z","shell.execute_reply.started":"2024-09-19T20:47:23.325042Z","shell.execute_reply":"2024-09-19T20:47:23.325067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fraud ve fraud olmayan işlemlerin yüzdelerini pie chart ile gösterir\n\ntotal = len(df['isFraud'])\ncount_0 = df['isFraud'].value_counts()[0]\ncount_1 = df['isFraud'].value_counts()[1]\nprint(count_1)\n\nper_count_0 = (count_0 / total) * 100\nper_count_1 = (count_1 / total) * 100\n\nlabels = ['Not Fraud', 'Fraud']\nsizes = [per_count_0, per_count_1]\ncolors = ['green', 'red']\n\nfig, ax = plt.subplots()\nax.pie(sizes, labels = labels, colors = colors, autopct='%1.1f%%')\nplt.title('Fraud vs Not Fraud Transactions')\nplt.show()\nprint('Percentage of Frauds:', per_count_1)\nprint('Percentage of Not Frauds:', per_count_0)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.327972Z","iopub.status.idle":"2024-09-19T20:47:23.328648Z","shell.execute_reply.started":"2024-09-19T20:47:23.328364Z","shell.execute_reply":"2024-09-19T20:47:23.328391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fraud işlemlerin fiyat aralıklarına göre dağılımının bar chart ile gösterimi\n\nbins = [0, 100000, 500000, 1000000, float('inf')]\nlabels = ['0-100K', '100K-500K', '500K-1M', '1M+']\n\n# Fraud işlemleri için 'amount' sütununu doğrudan gruplandırma yapılması\nfraud_df = df[df['isFraud'] == 1]\n\n# Yeni sütun oluşturmadan pd.cut ile gruplandırma ve sayım işlemi\nfraud_count_by_amount_range = pd.cut(fraud_df['amount'], bins=bins, labels=labels, right=False).value_counts().sort_index()\n\nplt.figure(figsize=(8, 6))\nax = fraud_count_by_amount_range.plot(kind='bar', color='red', edgecolor='black')\n\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width() / 2, \n            p.get_height() + 1,\n            int(p.get_height()),  # sayının integer formatında gösterilmesi\n            ha='center', va='bottom')\n\nplt.title('Fraud Transactions Count by Amount Range')\nplt.xlabel('Amount Range')\nplt.ylabel('Number of Fraud Transactions')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.330042Z","iopub.status.idle":"2024-09-19T20:47:23.330509Z","shell.execute_reply.started":"2024-09-19T20:47:23.330258Z","shell.execute_reply":"2024-09-19T20:47:23.330280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#isFlaggedFraud sütunundaki tahminlerin doğruluğunun oranınım pie chart ile gösterimi\n\ntrueFlag = ((df['isFraud'] == df['isFlaggedFraud'])).sum()\n\nfalseFlag = ((df['isFraud'] != df['isFlaggedFraud'])).sum()\n\ntotalDatas = len(df['isFraud'])\ntotal = trueFlag + falseFlag\n\ntrue_percentage = round((trueFlag / totalDatas) * 100, 2)\nfalse_percentage = round((falseFlag / totalDatas) * 100, 2)\n\nlabels = ['True Predictions', 'False Predictions']\nsizes = [true_percentage, false_percentage]\ncolors = ['green', 'red']\nexplode = (0, 0.1)\n\nfig, ax = plt.subplots()\nax.pie(sizes, explode=explode, labels=labels, colors = colors, autopct='%1.2f%%',\n       shadow=True, startangle=90)\nplt.title('True vs False Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.331739Z","iopub.status.idle":"2024-09-19T20:47:23.332214Z","shell.execute_reply.started":"2024-09-19T20:47:23.331967Z","shell.execute_reply":"2024-09-19T20:47:23.331991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"let = LabelEncoder() #Numerik olmayan veriler öğrenme algoritmaları için sorun yaratabilir\n#String veriler var ve bunları numeriğe çevirmek için label encoder fonksiyonu çağrılır.","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.333803Z","iopub.status.idle":"2024-09-19T20:47:23.334528Z","shell.execute_reply.started":"2024-09-19T20:47:23.334256Z","shell.execute_reply":"2024-09-19T20:47:23.334283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['type'] = let.fit_transform(df['type']) #Veriler numeriğe dönüştürülür\ncategory_mapping = dict(zip(let.classes_, let.transform(let.classes_))) #Dictionary veri yapısı kullanılarak hangi stringin hangi numerik değer aldığı gösterilir.\nprint(category_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.336586Z","iopub.status.idle":"2024-09-19T20:47:23.337072Z","shell.execute_reply.started":"2024-09-19T20:47:23.336800Z","shell.execute_reply":"2024-09-19T20:47:23.336825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Karmaşıklığı azaltıp algoritmanın performansı için \n\n#Denetimsiz öğrenme \ndf_2.drop(['nameOrig', 'nameDest', 'isFraud'], axis=1, inplace=True)\n\n#Denetimli öğrenme\ndf.drop(['nameOrig', 'nameDest'], axis=1, inplace=True) \ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.338178Z","iopub.status.idle":"2024-09-19T20:47:23.338655Z","shell.execute_reply.started":"2024-09-19T20:47:23.338396Z","shell.execute_reply":"2024-09-19T20:47:23.338421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Korelasyon haritasını gösterir\ncorr_matrix = df.corr()\nplt.figure(figsize=(20,15))\nsns.heatmap(corr_matrix, annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.340060Z","iopub.status.idle":"2024-09-19T20:47:23.340538Z","shell.execute_reply.started":"2024-09-19T20:47:23.340279Z","shell.execute_reply":"2024-09-19T20:47:23.340303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Denetimli öğrenme\ny = df['isFraud'].values\nX = df.drop('isFraud', axis=1).values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.341890Z","iopub.status.idle":"2024-09-19T20:47:23.342389Z","shell.execute_reply.started":"2024-09-19T20:47:23.342141Z","shell.execute_reply":"2024-09-19T20:47:23.342167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler() #Veriler farklı ölçeklerde olduğunda algoritmalara zorluk çıkartır. StandarScaler ile değerler 0 ile 1 arasında ölçeklenir ve bu da algoritmalar için yararlıdır\nX_train = scaler.fit_transform(X_train)\n\n#Denetimsiz öğrenme\nscaler_2 = StandardScaler()\ndf_scaled = scaler_2.fit_transform(df_2[['step', 'type', 'amount', 'isFlaggedFraud']]) #Korelasyon matrisinde değeri yüksek çıkan 4 sütun","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.343564Z","iopub.status.idle":"2024-09-19T20:47:23.344049Z","shell.execute_reply.started":"2024-09-19T20:47:23.343786Z","shell.execute_reply":"2024-09-19T20:47:23.343810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Yaptığım denemelerde en iyi sonucu verdiği için lojistik regresyonu seçtim. Tahmin yaptırdım ve değerlendirme metrikleriyle analiz ettim.\nlr = LogisticRegression(max_iter=1000)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.345304Z","iopub.status.idle":"2024-09-19T20:47:23.345785Z","shell.execute_reply.started":"2024-09-19T20:47:23.345533Z","shell.execute_reply":"2024-09-19T20:47:23.345557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Denetimsiz öğrenme\nparameters = {'C': [0.1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\nrandom_search = RandomizedSearchCV(\n    estimator=lr,\n    param_distributions=parameters,\n    n_iter=10,\n    cv=5,  # 5 katlamalı çapraz doğrulama\n    n_jobs=-1,  # Tüm işlemcileri kullan\n    verbose=1,\n    random_state=42\n)\n\nrandom_search.fit(X_train, y_train)\n\n# En iyi parametreleri ve skoru yazdıralım\nprint(\"En iyi parametreler:\", random_search.best_params_)\nprint(\"En iyi doğruluk skoru:\", random_search.best_score_)\n\n# En iyi model ile tahmin\nbest_model = random_search.best_estimator_\ny_pred = best_model.predict(X_test)\nlr_accuracy = accuracy_score(y_test, y_pred)\nlr_precision = precision_score(y_test, y_pred)\nlr_recall = recall_score(y_test, y_pred)\nlr_f1 = f1_score(y_test, y_pred)\n\nprint(\"Logistic Regression Classifier Performance:\")\nprint(\"Accuracy score: \", lr_accuracy)\nprint(\"Precision:\", lr_precision)\nprint(\"Recall:\", lr_recall)\nprint(\"F1 Score:\", lr_f1)\n\nlr_cm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix = lr_cm, display_labels = lr.classes_)\ndisp.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.347167Z","iopub.status.idle":"2024-09-19T20:47:23.347634Z","shell.execute_reply.started":"2024-09-19T20:47:23.347390Z","shell.execute_reply":"2024-09-19T20:47:23.347415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Denetimli öğrenme\nparam_grid = {\n    'eps': [0.3, 0.5, 0.7],\n    'min_samples': [5, 10, 15]\n}\n\nbest_eps = None\nbest_min_samples = None\nbest_silhouette_score = -1  # Silhouette skoru maksimuma çıkarılacak\nbest_dbscan_model = None\nbest_labels = None\n\nfor params in ParameterGrid(param_grid):\n    dbscan = DBSCAN(eps=params['eps'], min_samples=params['min_samples'])\n    labels = dbscan.fit_predict(X_preprocessed)\n    \n    # Eğer tek bir küme varsa (ya da sadece noise varsa), silhouette score hesaplanamaz\n    if len(set(labels)) > 1:\n        # Silhouette skoru ile değerlendirme\n        score = silhouette_score(X_preprocessed, labels)\n        print(f\"DBSCAN (eps={params['eps']}, min_samples={params['min_samples']}): Silhouette Score: {score}\")\n        \n        if score > best_silhouette_score:\n            best_silhouette_score = score\n            best_eps = params['eps']\n            best_min_samples = params['min_samples']\n            best_dbscan_model = dbscan\n            best_labels = labels\n\n# Optimize edilmiş modeli kullanarak nihai kümeleme\nprint(f\"En İyi Parametreler: eps={best_eps}, min_samples={best_min_samples}\")\nprint(f\"En İyi Silhouette Skoru: {best_silhouette_score}\")\n\n# Nihai küme etiketlerini DataFrame'e ekleme\ndf_2['DBSCAN_Label'] = best_labels\n\n# Anormal (fraud) verileri belirleme (DBSCAN'de -1 anormal verileri temsil eder)\nfraud_cases = df_2[df_2['DBSCAN_Label'] == -1]\n\nprint(\"Anormal (fraud) veriler:\")\nprint(fraud_cases.head())\n\n# Silhouette skoru ile değerlendirme\nsilhouette_avg = silhouette_score(X_preprocessed, best_labels)\nprint(f\"Final Silhouette Score: {silhouette_avg}\")\n\n# Davies-Bouldin İndeksi ile değerlendirme (daha düşük, daha iyi demektir)\ndavies_bouldin_avg = davies_bouldin_score(X_preprocessed, best_labels)\nprint(f\"Davies-Bouldin Score: {davies_bouldin_avg}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T20:47:23.348985Z","iopub.status.idle":"2024-09-19T20:47:23.349454Z","shell.execute_reply.started":"2024-09-19T20:47:23.349208Z","shell.execute_reply":"2024-09-19T20:47:23.349232Z"},"trusted":true},"execution_count":null,"outputs":[]}]}